import os
import re
import msgpack # Format binaire ultra-rapide
from .models import RuleVector, Pattern

class Exporter:
    """
    Exportateur de règles vers formats C++ (Hyperscan + msgpack).
    
    IMPLÉMENTATION LOGIQUE COMBINATOIRE HYPERSCAN (Recommandation IA Expert)
    ========================================================================
    
    Pour les règles multi-content (sémantique AND Snort), on utilise
    HS_FLAG_COMBINATION d'Hyperscan plutôt qu'une alternation (A|B|C).
    
    Avantages :
    - Sémantique EXACTE : pas de faux positifs
    - Hyperscan gère la logique AND en interne (performance optimale)
    - Pas besoin de vérification secondaire en C++
    
    Format patterns.txt :
    ---------------------
    # Section 1 : Patterns atomiques (regex individuels)
    1:/pattern_A/is
    2:/pattern_B/is
    3:/pattern_C/s
    
    # Section 2 : Expressions logiques combinatoires
    100001:(1 & 2)/c        <- Règle 1 : A AND B
    100002:(3)/c            <- Règle 2 : C seul
    100003:(1 & 2 & 3)/c    <- Règle 3 : A AND B AND C
    
    Le C++ référence les IDs logiques (100001, 100002...) dans rules_config.msgpack.
    """
    
    def __init__(self, output_dir):
        self.output_dir = output_dir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # Compteurs pour IDs uniques
        self._atomic_id_counter = 1
        self._logical_id_start = 100000  # IDs logiques commencent à 100000

    def export_all(self, firewall_rules, inspection_rules):
        print(f"[*] Démarrage de l'exportation vers {self.output_dir}...")
        
        # 1. Export iptables (Fast Path)
        self._export_iptables(firewall_rules, "firewall.sh")
        
        # 2. Export Hyperscan avec LOGIQUE COMBINATOIRE (Deep Path)
        hs_map, atomic_patterns = self._prepare_hyperscan_combinatorial_map(inspection_rules)
        self._export_hyperscan_patterns_combinatorial(hs_map, atomic_patterns, "patterns.txt")
        
        # 3. Export Binaire Contextuel (Deep Path - Logique IP/Port -> ID logique)
        self._export_binary_config(inspection_rules, hs_map, "rules_config.msgpack")
        
        print("[*] Exportation terminée avec succès.")

    def _export_iptables(self, rules: list[RuleVector], filename):
        """
        Génère un script bash pour iptables + ipset.
        """
        path = os.path.join(self.output_dir, filename)
        
        unique_ipsets = {}
        ipset_counter = 0
        rule_to_ipset = {}
        
        for idx, r in enumerate(rules):
            srcs = tuple(sorted(str(c) for c in r.src_ips.iter_cidrs()))
            
            if len(srcs) > 3:
                if srcs not in unique_ipsets:
                    ipset_name = f"fox_set{ipset_counter}"
                    unique_ipsets[srcs] = ipset_name
                    ipset_counter += 1
                rule_to_ipset[idx] = unique_ipsets[srcs]
            else:
                rule_to_ipset[idx] = None
        
        with open(path, 'w') as f:
            f.write("#!/bin/bash\n")
            f.write("# Generated by Fox Optimizer - Pure Firewall Rules\n\n")
            
            f.write("# 1. Setup Chain\n")
            f.write("iptables -N FOX_FILTER 2>/dev/null\n")
            f.write("iptables -F FOX_FILTER\n")
            f.write("iptables -D INPUT -j FOX_FILTER 2>/dev/null\n")
            f.write("iptables -I INPUT -j FOX_FILTER\n\n")
            
            if unique_ipsets:
                f.write(f"# 2. Creating {len(unique_ipsets)} shared IP sets\n")
                for cidrs, ipset_name in unique_ipsets.items():
                    f.write(f"ipset destroy {ipset_name} 2>/dev/null\n")
                    f.write(f"ipset create {ipset_name} hash:net\n")
                    for cidr in cidrs:
                        f.write(f"ipset add {ipset_name} {cidr}\n")
                    f.write("\n")
            
            f.write(f"# 3. Injecting {len(rules)} Firewall Rules\n")
            
            for idx, r in enumerate(rules):
                proto = r.proto.lower()
                if proto == "ip" or proto == "any":
                    proto_flag = ""
                else:
                    proto_flag = f" -p {proto}"
                
                dports = []
                for p in r.dst_ports.iter_cidrs():
                    if hasattr(p, 'first') and hasattr(p, 'last'):
                        if p.first == 0 and p.last == 65535:
                            continue
                        elif p.first == p.last:
                            dports.append(str(p.first))
                        else:
                            dports.append(f"{p.first}:{p.last}")
                
                action = "DROP"
                ipset_name = rule_to_ipset[idx]
                
                if ipset_name:
                    base_cmd = f"iptables -A FOX_FILTER{proto_flag} -m set --match-set {ipset_name} src"
                    if dports and proto in ["tcp", "udp"]:
                        chunk_size = 15
                        for i in range(0, len(dports), chunk_size):
                            chunk = ",".join(dports[i:i+chunk_size])
                            f.write(f"{base_cmd} -m multiport --dports {chunk} -j {action}\n")
                    else:
                        f.write(f"{base_cmd} -j {action}\n")
                else:
                    srcs = [str(c) for c in r.src_ips.iter_cidrs()]
                    for src in srcs:
                        base_cmd = f"iptables -A FOX_FILTER{proto_flag}"
                        if src != "0.0.0.0/0":
                            base_cmd += f" -s {src}"
                        if dports and proto in ["tcp", "udp"]:
                            chunk_size = 15
                            for i in range(0, len(dports), chunk_size):
                                chunk = ",".join(dports[i:i+chunk_size])
                                f.write(f"{base_cmd} -m multiport --dports {chunk} -j {action}\n")
                        else:
                            f.write(f"{base_cmd} -j {action}\n")

        try:
            os.chmod(path, 0o755)
        except: pass
        
        print(f"    -> Généré : {filename} ({len(rules)} règles)")

    def _prepare_hyperscan_combinatorial_map(self, rules: list[RuleVector]):
        """
        Implémente la LOGIQUE COMBINATOIRE HYPERSCAN.
        
        STRATÉGIE :
        ===========
        1. Patterns atomiques uniques (chaque pattern = 1 ID)
        2. Pour chaque règle :
           - Si AGRÉGÉE (flag _aggregated_or) : expression OR (ID1 | ID2 | ID3)
             → Si UN pattern matche → action (fusion de règles différentes)
           - Si MULTI-CONTENT originale : expression AND (ID1 & ID2 & ID3)
             → TOUS les patterns doivent matcher (sémantique Snort)
           - Si MONO-PATTERN : expression simple (ID)
        
        Résultat : ZÉRO faux positifs, sémantique exacte !
        """
        # Dictionnaire des patterns atomiques uniques
        unique_atomic_patterns = {}
        atomic_id_counter = 1
        
        # Mapping règle -> données Hyperscan
        hs_map = {}
        logical_id_counter = self._logical_id_start
        
        # Compteurs pour stats
        or_count = 0
        and_count = 0
        
        for r in rules:
            if not r.patterns:
                continue
            
            # Détecter si c'est une règle AGRÉGÉE (OR) ou multi-content originale (AND)
            is_aggregated_or = False
            if r.patterns and r.patterns[0].modifiers:
                is_aggregated_or = r.patterns[0].modifiers.get('_aggregated_or', False)
            
            # Collecter les IDs atomiques pour cette règle
            rule_atomic_ids = []
            
            for p in r.patterns:
                # Traitement du pattern
                processed = self._process_pattern_atomic(p)
                if not processed:
                    continue
                
                regex, flags = processed['expr'], processed['flags']
                pattern_key = (regex, flags)
                
                # Assignation d'un ID atomique unique (déduplication)
                if pattern_key not in unique_atomic_patterns:
                    unique_atomic_patterns[pattern_key] = {
                        'id': atomic_id_counter,
                        'regex': regex,
                        'flags': flags
                    }
                    atomic_id_counter += 1
                
                rule_atomic_ids.append(unique_atomic_patterns[pattern_key]['id'])
            
            if not rule_atomic_ids:
                continue
            
            # Génération de l'expression logique
            sorted_ids = sorted(list(set(rule_atomic_ids)))
            
            if len(sorted_ids) > 1:
                if is_aggregated_or:
                    # Règle AGRÉGÉE : OR (si UN matche → action)
                    expression = "(" + " | ".join(map(str, sorted_ids)) + ")"
                    or_count += 1
                else:
                    # Règle MULTI-CONTENT originale : AND (TOUS doivent matcher)
                    expression = "(" + " & ".join(map(str, sorted_ids)) + ")"
                    and_count += 1
            else:
                # Un seul pattern
                expression = f"({sorted_ids[0]})"
            
            # Assignation de l'ID logique final
            logical_id = logical_id_counter
            logical_id_counter += 1
            
            hs_map[r.id] = {
                'hs_id': logical_id,
                'expression': expression,
                'flags': 'c',  # HS_FLAG_COMBINATION obligatoire
                'atomic_ids': sorted_ids,
                'is_or': is_aggregated_or,
                'is_multi': len(sorted_ids) > 1
            }
        
        print(f"    - Patterns atomiques uniques : {len(unique_atomic_patterns)}")
        print(f"    - Expressions logiques : {len(hs_map)}")
        print(f"    - Règles agrégées (OR) : {or_count}")
        print(f"    - Règles multi-content (AND) : {and_count}")
        
        return hs_map, unique_atomic_patterns
    
    def _process_pattern_atomic(self, p: Pattern):
        """
        Traite un pattern individuel pour en faire un pattern atomique Hyperscan.
        Retourne {'expr': regex, 'flags': flags} ou None si invalide.
        """
        regex = p.string_val
        if not regex:
            return None
        
        # Nettoyage des modifiers Snort
        regex = self._clean_snort_modifiers(regex)
        
        # Échappement ou sanitization
        if not p.is_regex:
            # Content littéral : échapper les métacaractères regex
            regex = re.escape(regex)
        else:
            # PCRE : nettoyer les constructions problématiques
            regex = self._sanitize_regex(regex)
        
        # Conversion des séquences hex Snort |XX XX|
        regex = self._convert_hex_pipes(regex)
        
        if not regex:
            return None
        
        # Détermination des flags
        flags = ''
        modifiers_str = str(p.modifiers).lower() if p.modifiers else ''
        
        if 'nocase' in modifiers_str:
            flags += 'i'
        
        # DOTALL toujours activé pour DPI (. matche aussi \n)
        flags += 's'
        
        return {'expr': regex, 'flags': flags}
    
    def _export_hyperscan_patterns_combinatorial(self, hs_map, atomic_patterns, filename):
        """
        Génère patterns.txt au format COMBINATOIRE Hyperscan.
        
        Format :
        --------
        # Patterns atomiques
        1:/pattern_A/is
        2:/pattern_B/s
        
        # Expressions logiques (règles)
        100000:(1 & 2)/c
        100001:(2)/c
        """
        path = os.path.join(self.output_dir, filename)
        
        if not hs_map and not atomic_patterns:
            with open(path, 'w') as f:
                f.write("# No patterns\n")
            print(f"    -> Généré : {filename} (Vide)")
            return
        
        with open(path, 'w') as f:
            # Section 1 : Patterns atomiques
            f.write("# === ATOMIC PATTERNS (Individual Regex) ===\n")
            
            # Trier par ID pour stabilité
            sorted_atomic = sorted(atomic_patterns.values(), key=lambda x: x['id'])
            
            for atomic in sorted_atomic:
                # Échapper les slashs dans la regex pour le format fichier
                safe_expr = atomic['regex'].replace('/', '\\/')
                f.write(f"{atomic['id']}:/{safe_expr}/{atomic['flags']}\n")
            
            # Section 2 : Expressions logiques combinatoires
            f.write("\n# === LOGICAL EXPRESSIONS (Rule Combinations with HS_FLAG_COMBINATION) ===\n")
            
            # Trier par ID logique pour stabilité
            sorted_rules = sorted(hs_map.values(), key=lambda x: x['hs_id'])
            
            for rule_data in sorted_rules:
                # Format : ID:/expression/c
                # L'expression est déjà au format (1 & 2 & 3)
                f.write(f"{rule_data['hs_id']}:/{rule_data['expression']}/{rule_data['flags']}\n")
        
        print(f"    -> Généré : {filename} ({len(sorted_atomic)} atomic, {len(sorted_rules)} logical)")

    def _clean_snort_modifiers(self, s):
        """
        Enlève les modifiers Snort qui polluent les chaînes après fusion.
        Ex: 'payload",depth 16,nocase' -> 'payload'
        """
        # Pattern pour les modifiers Snort typiques
        # Ces modifiers sont souvent après un guillemet fermant
        snort_modifiers = [
            r'",\s*depth\s+\d+',
            r'",\s*offset\s+\d+',
            r'",\s*distance\s+\d+',
            r'",\s*within\s+\d+',
            r'",\s*fast_pattern(?:,\s*nocase)?',
            r'",\s*nocase',
            r',\s*fast_pattern_offset\s+\d+',
            r',\s*fast_pattern_length\s+\d+',
            r'",\s*fast_pattern,\s*nocase',
        ]
        
        result = s
        for mod in snort_modifiers:
            result = re.sub(mod, '', result, flags=re.IGNORECASE)
        
        # Nettoyer les guillemets orphelins
        result = result.strip('"').strip()
        
        return result
    
    def _convert_hex_pipes(self, s):
        """
        Convertit les séquences hex Snort en notation regex \\xHH.
        Gère à la fois |XX YY| (non échappé) et \\|XX YY\\| (après re.escape).
        Gère aussi les espaces échappés (\\ ) et les séquences sans espace (|0D0A|).
        """
        def hex_replacer(match):
            hex_content = match.group(1)
            # Nettoyer les espaces échappés (après re.escape, ' ' devient '\ ')
            hex_content = hex_content.replace('\\ ', ' ')
            
            # Split par espace ou traiter comme séquence continue
            if ' ' in hex_content:
                hex_bytes = hex_content.split()
            else:
                # Séquence continue sans espace: 0D0A -> ['0D', '0A']
                hex_bytes = [hex_content[i:i+2] for i in range(0, len(hex_content), 2)]
            
            # Filtrer les entrées valides (exactement 2 caractères hex)
            valid_bytes = [b for b in hex_bytes if len(b) == 2 and all(c in '0123456789ABCDEFabcdef' for c in b)]
            if not valid_bytes:
                return match.group(0)  # Pas de conversion possible
            # Convertir en \xHH notation
            return ''.join([f'\\x{b.upper()}' for b in valid_bytes])
        
        # Pattern pour matcher après re.escape: \|XX XX\| ou \|XXXX\|
        # re.escape transforme | en \| (1 backslash + pipe)
        # En regex raw string: r'\\\|' matche littéralement \|
        result = re.sub(r'\\\|([0-9A-Fa-f\\ ]+)\\\|', hex_replacer, s)
        # Puis le cas non-échappé (pour les pcre natifs): |XX XX|
        result = re.sub(r'\|([0-9A-Fa-f ]+)\|', hex_replacer, result)
        return result
    
    def _sanitize_regex(self, regex):
        """
        Nettoie et valide une regex pour Hyperscan.
        
        ATTENTION : Cette fonction est appelée UNIQUEMENT pour les PCRE natives
        provenant de Snort (is_regex=True dès le parsing).
        
        Les regex fusionnées par ContentEngine sont déjà correctement formées,
        on ne modifie donc que les cas problématiques spécifiques à Snort.
        """
        if not regex:
            return ''
        
        # Convertir les espaces échappés Snort '\ ' SEULEMENT au début/fin
        # (Snort utilise '\ ' pour les espaces significatifs dans content)
        # On ne touche PAS aux espaces internes des alternations/groupes
        
        # Enlever les échappements inutiles de slashes (Snort: \/ -> /)
        # MAIS seulement dans les PCRE natives, pas dans nos regex fusionnées
        if regex.startswith('/') or '\\/' in regex:
            regex = regex.replace('\\/', '/')
        
        # Vérifier les parenthèses équilibrées
        open_count = regex.count('(') - regex.count('\\(')
        close_count = regex.count(')') - regex.count('\\)')
        
        if open_count != close_count:
            # Log warning mais ne pas casser la regex
            # On retourne quand même, Hyperscan rejettera si invalide
            pass
        
        return regex

    def _export_binary_config(self, rules: list[RuleVector], hs_map, filename):
        """
        Sérialise la structure logique en MessagePack pour le C++.
        Contient : IP Src/Dst, Ports, Proto -> Lien vers ID Hyperscan.
        """
        path = os.path.join(self.output_dir, filename)
        
        data_to_serialize = []
        
        for r in rules:
            # On convertit les IPSets et PortSets en listes primitives (strings/ints)
            # pour que le C++ puisse les lire facilement.
            
            src_cidrs = [str(c) for c in r.src_ips.iter_cidrs()]
            dst_cidrs = [str(c) for c in r.dst_ips.iter_cidrs()]
            
            src_ports = []
            for p in r.src_ports.iter_cidrs():
                if hasattr(p, 'first'): src_ports.append([p.first, p.last])
                
            dst_ports = []
            for p in r.dst_ports.iter_cidrs():
                if hasattr(p, 'first'): dst_ports.append([p.first, p.last])

            # Lien vers Hyperscan (avec protection contre KeyError)
            hs_data = hs_map.get(r.id)
            if not hs_data:
                # Si la règle n'a pas de pattern valide, skip
                continue
            hs_id = hs_data['hs_id']
            
            # Structure de l'objet binaire
            rule_obj = {
                'id': r.id,
                'proto': r.proto,
                'src_ips': src_cidrs,
                'dst_ips': dst_cidrs,
                'src_ports': src_ports,
                'dst_ports': dst_ports,
                'direction': r.direction,
                'hs_id': hs_id, # Le lien vital !
                'action': r.action
            }
            data_to_serialize.append(rule_obj)
            
        with open(path, 'wb') as f:
            packed = msgpack.packb(data_to_serialize)
            f.write(packed)
            
        print(f"    -> Généré : {filename} ({len(packed)/1024:.2f} KB)")