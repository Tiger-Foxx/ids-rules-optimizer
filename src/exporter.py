import os
import re
import msgpack # Format binaire ultra-rapide
from .models import RuleVector

class Exporter:
    def __init__(self, output_dir):
        self.output_dir = output_dir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

    def export_all(self, firewall_rules, inspection_rules):
        print(f"[*] Démarrage de l'exportation vers {self.output_dir}...")
        
        # 1. Export iptables (Fast Path)
        self._export_iptables(firewall_rules, "firewall.sh")
        
        # 2. Export Hyperscan (Deep Path - Patterns)
        # On doit d'abord mapper les règles à des IDs uniques pour Hyperscan
        hs_map = self._prepare_hyperscan_map(inspection_rules)
        self._export_hyperscan_patterns(hs_map, "patterns.txt")
        
        # 3. Export Binaire Contextuel (Deep Path - Logique IP/Port -> Pattern ID)
        self._export_binary_config(inspection_rules, hs_map, "rules_config.msgpack")
        
        print("[*] Exportation terminée avec succès.")

    def _export_iptables(self, rules: list[RuleVector], filename):
        """
        Génère un script bash pour iptables + ipset.
        
        OPTIMISATION AVANCÉE:
        1. Détecte les ensembles d'IPs identiques entre règles
        2. Crée un ipset partagé par ensemble unique
        3. Réutilise l'ipset pour toutes les règles qui le partagent
        """
        path = os.path.join(self.output_dir, filename)
        
        # Phase 1: Identifier les ensembles d'IPs uniques
        # Clé = tuple trié des CIDRs, Valeur = nom de l'ipset
        unique_ipsets = {}
        ipset_counter = 0
        rule_to_ipset = {}  # rule_index -> ipset_name (ou None si simple)
        
        for idx, r in enumerate(rules):
            srcs = tuple(sorted(str(c) for c in r.src_ips.iter_cidrs()))
            
            if len(srcs) > 3:
                if srcs not in unique_ipsets:
                    ipset_name = f"fox_set{ipset_counter}"
                    unique_ipsets[srcs] = ipset_name
                    ipset_counter += 1
                rule_to_ipset[idx] = unique_ipsets[srcs]
            else:
                rule_to_ipset[idx] = None
        
        with open(path, 'w') as f:
            f.write("#!/bin/bash\n")
            f.write("# Generated by Fox Optimizer - Pure Firewall Rules\n")
            f.write("# IMPORTANT: Run as root! Requires ipset package.\n\n")
            
            # Setup de la chaîne
            f.write("# 1. Setup Chain\n")
            f.write("iptables -N FOX_FILTER 2>/dev/null\n")
            f.write("iptables -F FOX_FILTER\n")
            f.write("iptables -D INPUT -j FOX_FILTER 2>/dev/null\n")
            f.write("iptables -I INPUT -j FOX_FILTER\n\n")
            
            # Phase 2: Créer les ipsets uniques (une seule fois chacun)
            if unique_ipsets:
                f.write(f"# 2. Creating {len(unique_ipsets)} shared IP sets\n")
                for cidrs, ipset_name in unique_ipsets.items():
                    f.write(f"ipset destroy {ipset_name} 2>/dev/null\n")
                    f.write(f"ipset create {ipset_name} hash:net\n")
                    for cidr in cidrs:
                        f.write(f"ipset add {ipset_name} {cidr}\n")
                    f.write("\n")
            
            # Phase 3: Générer les règles iptables
            f.write(f"# 3. Injecting {len(rules)} Firewall Rules\n")
            
            for idx, r in enumerate(rules):
                proto = r.proto.lower()
                if proto == "ip" or proto == "any":
                    proto_flag = ""
                else:
                    proto_flag = f" -p {proto}"
                
                # Gestion Ports Destination
                dports = []
                for p in r.dst_ports.iter_cidrs():
                    if hasattr(p, 'first') and hasattr(p, 'last'):
                        if p.first == 0 and p.last == 65535:
                            continue
                        elif p.first == p.last:
                            dports.append(str(p.first))
                        else:
                            dports.append(f"{p.first}:{p.last}")
                
                action = "DROP"
                ipset_name = rule_to_ipset[idx]
                
                if ipset_name:
                    # Utiliser l'ipset partagé
                    base_cmd = f"iptables -A FOX_FILTER{proto_flag} -m set --match-set {ipset_name} src"
                    
                    if r.icmp_type and proto == "icmp":
                        base_cmd += f" --icmp-type {r.icmp_type}"
                    
                    if r.tcp_flags and proto == "tcp":
                        if "S" in r.tcp_flags and "A" not in r.tcp_flags:
                            base_cmd += " --syn"
                    
                    if dports and proto in ["tcp", "udp"]:
                        chunk_size = 15
                        for i in range(0, len(dports), chunk_size):
                            chunk = ",".join(dports[i:i+chunk_size])
                            f.write(f"{base_cmd} -m multiport --dports {chunk} -j {action}\n")
                    else:
                        f.write(f"{base_cmd} -j {action}\n")
                else:
                    # Règles simples (peu de CIDRs)
                    srcs = [str(c) for c in r.src_ips.iter_cidrs()]
                    for src in srcs:
                        base_cmd = f"iptables -A FOX_FILTER{proto_flag}"
                        
                        if src != "0.0.0.0/0":
                            base_cmd += f" -s {src}"
                        
                        if r.tcp_flags and proto == "tcp":
                            if "S" in r.tcp_flags and "A" not in r.tcp_flags:
                                base_cmd += " --syn"
                        
                        if r.icmp_type and proto == "icmp":
                            base_cmd += f" --icmp-type {r.icmp_type}"
                        
                        if dports and proto in ["tcp", "udp"]:
                            chunk_size = 15
                            for i in range(0, len(dports), chunk_size):
                                chunk = ",".join(dports[i:i+chunk_size])
                                f.write(f"{base_cmd} -m multiport --dports {chunk} -j {action}\n")
                        else:
                            f.write(f"{base_cmd} -j {action}\n")

        try:
            os.chmod(path, 0o755)
        except: pass
        
        stats = f"{len(rules)} règles, {len(unique_ipsets)} ipsets partagés"
        print(f"    -> Généré : {filename} ({stats})")

    def _prepare_hyperscan_map(self, rules: list[RuleVector]):
        """
        Associe chaque règle d'inspection à un ID unique pour Hyperscan.
        Retourne une map {rule_id: {'hs_id': int, 'patterns': list[str]}}
        """
        hs_map = {}
        hs_counter = 1
        
        for r in rules:
            # On génère un ID pour le groupe de patterns de cette règle
            current_hs_id = hs_counter
            hs_counter += 1
            
            # Conversion des patterns en regex compatibles Hyperscan
            regex_list = []
            for p in r.patterns:
                regex = p.string_val
                
                # 0. NETTOYAGE CRITIQUE : Enlever les modifiers Snort de la chaîne
                # Ces modifiers sont parfois inclus après la fusion sémantique
                regex = self._clean_snort_modifiers(regex)
                
                # 2. Echappement si ce n'est pas déjà une regex (content simple)
                if not p.is_regex:
                    # Pour les patterns simples, on échappe les caractères spéciaux regex
                    regex = re.escape(regex)
                else:
                    # Pour les regex, on valide et nettoie
                    regex = self._sanitize_regex(regex)
                
                # 1. Conversion Hex APRÈS escape : \|XX XX\| -> \xHH\xHH
                # re.escape() transforme |XX| en \|XX\|, donc on matche ça
                regex = self._convert_hex_pipes(regex)
                
                # Skip les patterns vides ou invalides
                if not regex or len(regex) < 1:
                    continue
                
                # 3. Modifiers (nocase) -> flag 'i'
                flags = ''
                if 'nocase' in str(p.modifiers).lower():
                    flags = 'i'
                
                regex_entry = {
                    'expr': regex,
                    'flags': flags
                }
                regex_list.append(regex_entry)
            
            # Skip les règles sans patterns valides
            if regex_list:
                hs_map[r.id] = {
                    'hs_id': current_hs_id,
                    'regex_list': regex_list
                }
            
        return hs_map

    def _clean_snort_modifiers(self, s):
        """
        Enlève les modifiers Snort qui polluent les chaînes après fusion.
        Ex: 'payload",depth 16,nocase' -> 'payload'
        """
        # Pattern pour les modifiers Snort typiques
        # Ces modifiers sont souvent après un guillemet fermant
        snort_modifiers = [
            r'",\s*depth\s+\d+',
            r'",\s*offset\s+\d+',
            r'",\s*distance\s+\d+',
            r'",\s*within\s+\d+',
            r'",\s*fast_pattern(?:,\s*nocase)?',
            r'",\s*nocase',
            r',\s*fast_pattern_offset\s+\d+',
            r',\s*fast_pattern_length\s+\d+',
            r'",\s*fast_pattern,\s*nocase',
        ]
        
        result = s
        for mod in snort_modifiers:
            result = re.sub(mod, '', result, flags=re.IGNORECASE)
        
        # Nettoyer les guillemets orphelins
        result = result.strip('"').strip()
        
        return result
    
    def _convert_hex_pipes(self, s):
        """
        Convertit les séquences hex Snort en notation regex \\xHH.
        Gère à la fois |XX YY| (non échappé) et \\|XX YY\\| (après re.escape).
        Gère aussi les espaces échappés (\\ ) et les séquences sans espace (|0D0A|).
        """
        def hex_replacer(match):
            hex_content = match.group(1)
            # Nettoyer les espaces échappés (après re.escape, ' ' devient '\ ')
            hex_content = hex_content.replace('\\ ', ' ')
            
            # Split par espace ou traiter comme séquence continue
            if ' ' in hex_content:
                hex_bytes = hex_content.split()
            else:
                # Séquence continue sans espace: 0D0A -> ['0D', '0A']
                hex_bytes = [hex_content[i:i+2] for i in range(0, len(hex_content), 2)]
            
            # Filtrer les entrées valides (exactement 2 caractères hex)
            valid_bytes = [b for b in hex_bytes if len(b) == 2 and all(c in '0123456789ABCDEFabcdef' for c in b)]
            if not valid_bytes:
                return match.group(0)  # Pas de conversion possible
            # Convertir en \xHH notation
            return ''.join([f'\\x{b.upper()}' for b in valid_bytes])
        
        # Pattern pour matcher après re.escape: \|XX XX\| ou \|XXXX\|
        # re.escape transforme | en \| (1 backslash + pipe)
        # En regex raw string: r'\\\|' matche littéralement \|
        result = re.sub(r'\\\|([0-9A-Fa-f\\ ]+)\\\|', hex_replacer, s)
        # Puis le cas non-échappé (pour les pcre natifs): |XX XX|
        result = re.sub(r'\|([0-9A-Fa-f ]+)\|', hex_replacer, result)
        return result
    
    def _sanitize_regex(self, regex):
        """
        Nettoie et valide une regex pour Hyperscan.
        """
        # Enlever les backslashes avant les espaces (Snort: '\ ' -> ' ')
        regex = regex.replace('\\ ', ' ')
        
        # Enlever les échappements inutiles
        regex = regex.replace('\\/', '/')
        
        # Vérifier les parenthèses équilibrées
        if regex.count('(') != regex.count(')'):
            # Tenter de réparer ou retourner une version simplifiée
            # En cas de déséquilibre, on échappe tout
            return re.escape(regex.replace('(', '').replace(')', ''))
        
        return regex

    def _export_hyperscan_patterns(self, hs_map, filename):
        """
        Génère le fichier patterns.txt pour le compilateur Hyperscan.
        Format: ID:/regex/flags
        """
        path = os.path.join(self.output_dir, filename)
        with open(path, 'w') as f:
            for rule_id, data in hs_map.items():
                hs_id = data['hs_id']
                for regex_entry in data['regex_list']:
                    expr = regex_entry['expr']
                    flags = regex_entry['flags']
                    # Format Hyperscan standard
                    # ID:/regex/flags
                    # Attention aux slashs dans la regex, il faut les échapper pour ce format fichier
                    safe_expr = expr.replace('/', '\\/')
                    f.write(f"{hs_id}:/{safe_expr}/{flags}\n")
        print(f"    -> Généré : {filename}")

    def _export_binary_config(self, rules: list[RuleVector], hs_map, filename):
        """
        Sérialise la structure logique en MessagePack pour le C++.
        Contient : IP Src/Dst, Ports, Proto -> Lien vers ID Hyperscan.
        """
        path = os.path.join(self.output_dir, filename)
        
        data_to_serialize = []
        
        for r in rules:
            # On convertit les IPSets et PortSets en listes primitives (strings/ints)
            # pour que le C++ puisse les lire facilement.
            
            src_cidrs = [str(c) for c in r.src_ips.iter_cidrs()]
            dst_cidrs = [str(c) for c in r.dst_ips.iter_cidrs()]
            
            src_ports = []
            for p in r.src_ports.iter_cidrs():
                if hasattr(p, 'first'): src_ports.append([p.first, p.last])
                
            dst_ports = []
            for p in r.dst_ports.iter_cidrs():
                if hasattr(p, 'first'): dst_ports.append([p.first, p.last])

            # Lien vers Hyperscan
            hs_id = hs_map[r.id]['hs_id']
            
            # Structure de l'objet binaire
            rule_obj = {
                'id': r.id,
                'proto': r.proto,
                'src_ips': src_cidrs,
                'dst_ips': dst_cidrs,
                'src_ports': src_ports,
                'dst_ports': dst_ports,
                'direction': r.direction,
                'hs_id': hs_id, # Le lien vital !
                'action': r.action
            }
            data_to_serialize.append(rule_obj)
            
        with open(path, 'wb') as f:
            packed = msgpack.packb(data_to_serialize)
            f.write(packed)
            
        print(f"    -> Généré : {filename} ({len(packed)/1024:.2f} KB)")